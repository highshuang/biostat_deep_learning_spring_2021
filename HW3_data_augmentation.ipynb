{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "HW3_data_augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/highshuang/biostat_deep_learning_spring_2021/blob/develop/HW3_data_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAHqq-HaHlvf",
        "outputId": "b90a8414-30e9-4377-e1b9-1b2c800e6503"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import tensorflow.keras as keras #\n",
        "import numpy as np\n",
        "##import data: \n",
        "## mount your google drive: \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoJ_gHK2JV01"
      },
      "source": [
        "#!pip install imgaug\n",
        "import imageio\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEOHi9DQJG1y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "outputId": "3b420d82-c59a-4206-cdc8-2d8a5fc731b2"
      },
      "source": [
        "##path = 'drive/My Drive/deep-learning-colab/mnist.npz'\n",
        "path = 'mnist.npz'\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data(path)\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "fig, axs = plt.subplots(2,2)\n",
        "for ii in np.arange(0,2):\n",
        "    for jj in np.arange(0,2):\n",
        "        axs[ii,jj].imshow(train_images[ii*2+jj,:,:])\n",
        "        axs[ii,jj].title.set_text(train_labels[ii*2+jj])\n",
        "##print(range(0,2))\n",
        "##plt.show()\n",
        "\n",
        "# example of the image transformation \n",
        "image = train_images[0,:,:]\n",
        "ia.imshow(image)\n",
        "\n",
        "# 1. rotation between -50 degree to 30 degree\n",
        "rotate=iaa.Affine(rotate=(-50, 30))\n",
        "rotated_image=rotate.augment_image(image)\n",
        "ia.imshow(rotated_image)\n",
        "\n",
        "# 2. additive gaussian noise \n",
        "gaussian_noise=iaa.AdditiveGaussianNoise(10,20)\n",
        "noise_image=gaussian_noise.augment_image(image)\n",
        "ia.imshow(noise_image)\n",
        "\n",
        "# 3. shearing \n",
        "shear = iaa.Affine(shear=(0,40))\n",
        "shear_image=shear.augment_image(image)\n",
        "ia.imshow(shear_image)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x28 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x28 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x28 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x28 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nybEaCfXy2Dw"
      },
      "source": [
        "Here, the MNIST dataset has 60000 rows of data points and sample size is relatively small. What we can consider is applying image augmentation to artificially create variations. In this way, we can achieve a rich and diverse data, in order to increase the performance of the model and reduce overfittting.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmgQo_1oZ9nc",
        "outputId": "b5183ebf-8fea-44a9-95de-08d5153ab7e3"
      },
      "source": [
        "# Data augmentation technique 1: rotation between -50 to 30 degrees\n",
        "train_rotate =[]\n",
        "\n",
        "for i in np.arange(0, 60000):\n",
        "  image = train_images[i,:,:]\n",
        "  rotate=iaa.Affine(rotate=(-50, 30))\n",
        "  rotated_image=rotate.augment_image(image)\n",
        "  train_rotate.append(rotated_image)\n",
        "\n",
        "train_rotate = np.asarray(train_rotate)\n",
        "print(train_rotate.shape)\n",
        "\n",
        "train_rotate = np.concatenate((train_images, train_rotate), axis=0)\n",
        "print(train_rotate.shape)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(120000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXTQUH4KsATg",
        "outputId": "9368f9fe-41cd-47dd-92d2-888a7ad4be54"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# construct a dense NN \n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "network.compile(optimizer='rmsprop',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "\n",
        "# prepare the dimension and type of input data \n",
        "path = 'mnist.npz'\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data(path)\n",
        "train_rotate = train_rotate.reshape((120000, 28 * 28))\n",
        "train_rotate = train_rotate.astype('float32') / 255\n",
        "#train_shear = train_shear.reshape((120000, 28 * 28))\n",
        "#train_shear = train_shear.astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "train_rotate_labels = np.concatenate((train_labels,train_labels),axis = 0)\n",
        "#train_shear_labels = train_rotate_labels\n",
        "print(train_rotate_labels.shape)\n",
        "\n",
        "# prepare the label format\n",
        "from keras.utils import to_categorical\n",
        "train_rotate_labels = to_categorical(train_rotate_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "print(train_rotate_labels.shape)\n",
        "\n",
        "# fit the model \n",
        "network.fit(train_rotate, train_rotate_labels, epochs=5, batch_size=128)\n",
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "print(test_acc)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120000,)\n",
            "(120000, 10)\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 2.3016 - accuracy: 0.1108\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 2.3010 - accuracy: 0.1136\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 2.3003 - accuracy: 0.1134\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 2.2975 - accuracy: 0.1141\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 2.2906 - accuracy: 0.1249\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 22.3938 - accuracy: 0.3575\n",
            "0.35749998688697815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnd1MCjMqRdX",
        "outputId": "8b915633-9d34-48a7-ac1a-c025d47bcc28"
      },
      "source": [
        "# Data augmentation technique 2: Shearing the image by 0 to 40 degrees\n",
        "train_shear =[]\n",
        "\n",
        "for i in np.arange(0, 60000):\n",
        "  image = train_images[i,:,:]\n",
        "  shear = iaa.Affine(shear=(0,40))\n",
        "  shear_image=shear.augment_image(image)\n",
        "  train_shear.append(shear_image)\n",
        "\n",
        "train_shear = np.asarray(train_shear)\n",
        "print(train_shear.shape)\n",
        "\n",
        "train_shear = np.concatenate((train_images, train_shear), axis=0)\n",
        "print(train_shear.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(120000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEoU1rGNwQDG",
        "outputId": "583d70d4-3ab1-439b-8131-830b076c3aa7"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# construct a dense NN \n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "network.compile(optimizer='rmsprop',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "\n",
        "# prepare the dimension and type of input data \n",
        "path = 'mnist.npz'\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data(path)\n",
        "train_shear = train_shear.reshape((120000, 28 * 28))\n",
        "train_shear = train_shear.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "train_shear_labels = np.concatenate((train_labels,train_labels),axis = 0)\n",
        "\n",
        "print(train_shear_labels.shape)\n",
        "\n",
        "# prepare the label format\n",
        "from keras.utils import to_categorical\n",
        "train_shear_labels = to_categorical(train_shear_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "train_shear_labels.shape\n",
        "\n",
        "# fit the model \n",
        "network.fit(train_shear, train_shear_labels, epochs=5, batch_size=128)\n",
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120000,)\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 0.3732 - accuracy: 0.8906\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0921 - accuracy: 0.9730\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0586 - accuracy: 0.9829\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0420 - accuracy: 0.9872\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0346 - accuracy: 0.9895\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.9816\n",
            "0.9815999865531921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JROzBNMra4B",
        "outputId": "498d0d49-a964-48c7-f1c1-918ae9c52258"
      },
      "source": [
        "# Data augmentation technique 3: Adding noise to the image\n",
        "train_noise =[]\n",
        "\n",
        "for i in np.arange(0, 60000):\n",
        "  image = train_images[i,:,:]\n",
        "  gaussian_noise=iaa.AdditiveGaussianNoise(10,20)\n",
        "  noise_image=gaussian_noise.augment_image(image)\n",
        "  train_noise.append(noise_image)\n",
        "\n",
        "train_noise = np.asarray(train_noise)\n",
        "print(train_noise.shape)\n",
        "\n",
        "train_noise = np.concatenate((train_images, train_noise), axis=0)\n",
        "print(train_noise.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(120000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ75ELKHwQjt",
        "outputId": "f67c9a96-d33d-4794-882e-449bb229d026"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# construct a dense NN \n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "network.compile(optimizer='rmsprop',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "\n",
        "# prepare the dimension and type of input data \n",
        "path = 'mnist.npz'\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data(path)\n",
        "train_noise = train_noise.reshape((120000, 28 * 28))\n",
        "train_noise = train_noise.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "train_noise_labels = np.concatenate((train_labels,train_labels),axis = 0)\n",
        "\n",
        "print(train_noise_labels.shape)\n",
        "\n",
        "# prepare the label format\n",
        "from keras.utils import to_categorical\n",
        "train_noise_labels = to_categorical(train_noise_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "train_noise_labels.shape\n",
        "\n",
        "# fit the model \n",
        "network.fit(train_noise, train_noise_labels, epochs=5, batch_size=128)\n",
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "print(test_acc)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120000,)\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 0.3499 - accuracy: 0.8966\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0692 - accuracy: 0.9784\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0364 - accuracy: 0.9885\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0209 - accuracy: 0.9938\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0128 - accuracy: 0.9961\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0676 - accuracy: 0.9821\n",
            "0.9821000099182129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JkPVMoOd1f7"
      },
      "source": [
        "Results:\n",
        "1. With no data augmentation, the accuracy on test data is 0.9795. \n",
        "2. With rotation, the accuracy on test data is 0.3575.\n",
        "3. With adding guassian noise to the images, teh accuracy on the test data is 0.9821, which has better performance than the fitting without data augmentation. \n",
        "4. With adding guassian noise to the images, teh accuracy on the test data is 0.9816, which has better performance than the fitting without data augmentation. \n",
        "\n",
        "Discussion:\n",
        "1. It is not surprising to have a very poor performance when apply the rotation transformation. When we consider the handwritten digits, it might not be useful to use rotation transformation. Because for digit 6, rotation may increase ambiguity between digit 6 and 9. With the similar reason, flipping and zooming would also not give a better preformance or even give a lot of misclassifications.\n",
        "2. For adding guassian noise, this transformation still keeps the features of the digits and add the random noise to prevent overfitting. As we can see in the result, it gives a slightly better performance than the one with no data augmentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3WRVjZu0eGj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}